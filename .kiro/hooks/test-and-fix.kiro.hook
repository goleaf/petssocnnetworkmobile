{
  "enabled": true,
  "name": "Test Runner & Auto-Fixer",
  "description": "Automatically runs relevant tests after code changes and attempts to fix any failures found",
  "version": "1",
  "when": {
    "type": "fileEdited",
    "patterns": [
      "app/**/*.{ts,tsx,js,jsx}",
      "components/**/*.{ts,tsx,js,jsx}",
      "lib/**/*.{ts,tsx,js,jsx}"
    ]
  },
  "then": {
    "type": "askAgent",
    "prompt": "A source file has been modified: {{changedFiles}}\n\n## Step 1: Identify Test Scope\nAnalyze the changed file path and determine which tests to run:\n\n**Test Location Mapping:**\n- `app/api/**` → `tests/active/api/**/*.test.ts`\n- `app/**` (pages/layouts) → `tests/active/app/**/*.test.tsx`\n- `components/**` → `tests/active/components/**/*.test.tsx`\n- `lib/**` → `tests/active/lib/**/*.test.ts`\n- Integration flows → `tests/active/integration/*.test.ts`\n- Profile features → `tests/active/profile/*.test.tsx`\n\n**Test Discovery Strategy:**\n1. Extract the base filename (e.g., `privacy.ts` → `privacy`)\n2. Search for matching test files in `tests/active/` subdirectories\n3. If no exact match, look for tests that import the changed file\n4. For utilities in `lib/`, check both `tests/active/lib/` and integration tests\n\n## Step 2: Run TypeCheck First\nBefore running tests, catch type errors early:\n```bash\nnpm run typecheck\n```\nIf type errors exist, fix them before proceeding to tests.\n\n## Step 3: Run Targeted Tests\nExecute the most specific test command:\n\n**For specific test files:**\n```bash\nnpm test -- <test-filename>\n```\n\n**For directory patterns:**\n```bash\nnpm test -- tests/active/api/  # All API tests\nnpm test -- tests/active/components/  # All component tests\n```\n\n**For full suite (if changes are widespread):**\n```bash\nnpm test\n```\n\n## Step 4: Analyze Failures\nIf tests fail, categorize the error:\n\n**Type Errors:**\n- Missing/incorrect type annotations\n- Interface/type mismatches\n- Generic constraints violations\n- Import path issues with `@/` alias\n\n**Test Assertion Failures:**\n- Outdated expectations (implementation changed intentionally)\n- Mock/stub mismatches (function signatures changed)\n- Missing test setup (beforeEach/afterEach)\n- Snapshot mismatches (UI changed)\n\n**Runtime Errors:**\n- Missing imports or undefined references\n- Mock configuration issues (check `jest.config.js` moduleNameMapper)\n- Environment setup problems (check `jest.setup.js`)\n- Async/promise handling issues\n\n**Logic Errors:**\n- Implementation bugs\n- Edge cases not handled\n- Incorrect business logic\n- Missing error handling\n\n## Step 5: Apply Fixes\n\n**For Type Errors:**\n1. Add explicit return types to functions\n2. Fix type imports and exports\n3. Update interface definitions\n4. Ensure `@/` alias resolves correctly\n\n**For Test Failures:**\n1. Update test expectations if implementation changed intentionally\n2. Fix mocks to match new function signatures\n3. Update `__mocks__/` files if needed\n4. Regenerate snapshots with `npm test -- -u` if UI changed\n\n**For Mock Issues:**\n1. Check `jest.config.js` moduleNameMapper for correct paths\n2. Update mocks in `__mocks__/` directory\n3. Verify `jest.setup.js` and `jest.setup.preenv.js` configurations\n4. Ensure manual mocks in `tests/unit/` are up to date\n\n**For Logic Errors:**\n1. Fix the implementation bug in the source file\n2. Add defensive checks and validation\n3. Handle edge cases properly\n4. Improve error messages and handling\n\n## Step 6: Verify Fixes\nAfter applying fixes, run the verification sequence:\n\n1. **Re-run the specific tests:**\n   ```bash\n   npm test -- <test-filename>\n   ```\n\n2. **Run typecheck:**\n   ```bash\n   npm run typecheck\n   ```\n\n3. **Run linter:**\n   ```bash\n   npm run lint\n   ```\n\n4. **If all pass, run full test suite to catch regressions:**\n   ```bash\n   npm test\n   ```\n\n## Step 7: Report Results\nProvide a concise summary:\n\n```\n✓ Changed: <file-path>\n✓ Tests run: <test-file-names>\n✓ Failures found: <count> (<brief description>)\n✓ Fixes applied: <list of changes>\n✓ Status: <passing/failing>\n✓ Coverage: <maintained/improved/reduced>\n```\n\nIf issues remain, explain what needs manual attention and why.\n\n## Important Guidelines\n\n**Code Quality:**\n- Follow 2-space indentation (project standard)\n- Use explicit return types on exported functions\n- Prefer PascalCase for components, camelCase for utilities\n- Add `\"use client\"` directive for client-side React files\n- Use `cn()` helper for Tailwind class composition\n\n**Testing Standards:**\n- All tests must live in `tests/active/` to be executed\n- Maintain 80% coverage threshold (branches, functions, lines, statements)\n- Use `data-testid` selectors for E2E tests\n- Colocate domain logic tests near their sources\n- Reuse `__mocks__/` for auth/network doubles\n\n**Fix Constraints:**\n- Preserve existing functionality unless fixing a bug\n- Keep changes minimal and focused\n- Don't delete tests to make them pass\n- Don't change test expectations without understanding why they fail\n- If significant refactoring is needed, explain and ask for confirmation\n\n**Repository Patterns:**\n- Server data access belongs in `lib/`, not React trees\n- Use Zod schemas for validation (colocate with domain logic)\n- Rely on ESLint autofix before committing\n- Check `jest.config.js` for module resolution rules\n- Consult `TEST_RUNNING_INSTRUCTIONS.md` for E2E test guidance\n\n## Example Workflow\n\n```\n1. Changed: lib/utils/privacy.ts\n2. TypeCheck: ✓ No errors\n3. Running: npm test -- privacy.test.ts\n4. Found: 2 failures\n   - Type error: Property 'userId' missing on PrivacySettings\n   - Assertion: Expected 'friends' but got 'public'\n5. Fixes:\n   - Added userId: string to PrivacySettings interface\n   - Updated default privacy level from 'public' to 'friends'\n6. Re-running: npm test -- privacy.test.ts\n7. Result: ✓ All 12 tests passing\n8. TypeCheck: ✓ No errors\n9. Lint: ✓ No issues\n10. Coverage: Maintained at 85%\n```\n\nfor all editing use mcp\n\nBegin the workflow now."
  }
}